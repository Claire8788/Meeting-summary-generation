# Meeting-summary-generation
主要包括以下关键节点：

数据准备
模型训练
模型格式转化
服务端部署与启动
API服务编写与部署
客户端(网页端的编写与部署）


BERT模型： 首先需要获取预训练的BERT模型的权重参数和配置文件。您可以从Hugging Face的模型库（https://huggingface.co/models）或TensorFlow官方的模型库中获取预训练的BERT模型。

编码器（Encoder）： 使用BERT模型作为编码器来将学术文章编码为语义表示。您可以使用相应的BERT模型加载器加载预训练的BERT模型，并通过它来编码输入的文章。

解码器（Decoder）： 在BERT模型的顶部添加额外的层来执行生成摘要的任务。这些额外的层可以是全连接层、注意力层等，用于将BERT编码的语义表示转换为摘要的形式。

数据集： 您需要准备一个标注好的数据集，其中包含了学术文章及其对应的摘要。这个数据集将用于微调BERT模型，以适应生成摘要的任务。

训练脚本： 编写训练脚本，包括加载预训练的BERT模型、定义解码器层、读取数据集、执行微调等步骤。您可以使用TensorFlow、PyTorch等深度学习框架来实现训练脚本。

评估脚本： 编写评估脚本，用于评估微调后的模型在生成摘要任务上的性能。您可以使用BLEU指标等标准的自然语言处理评估方法来评估生成的摘要与标准摘要之间的相似度。

推理脚本： 编写推理脚本，用于使用微调后的模型生成学术文章摘要。您可以使用训练好的模型来对新的学术文章进行摘要生成。

# 数据集
演讲会议文稿 视频
学术会议报告
企业会议文稿
